# zhiweidata-crawler 的文本编码修复实现：

向 okhttp 注册自定义拦截器，最终处理响应的拦截器列表如下：

com.zhiwei.crawler.core.DecodingChineseInterceptor
com.zhiwei.crawler.core.UncompressBodyInterceptor
com.zhiwei.crawler.core.ProxyRetryInterceptor
okhttp3.internal.http.RetryAndFollowUpInterceptor
okhttp3.internal.http.BridgeInterceptor
okhttp3.internal.cache.CacheInterceptor
okhttp3.internal.connection.ConnectInterceptor
okhttp3.internal.http.CallServerInterceptor

okhttp3 自带的几个拦截器与文本修复无关，直接忽略即可。拦截器处理数据的顺序是从下往上，以这三个拦截器为例：
com.zhiwei.crawler.core.DecodingChineseInterceptor
com.zhiwei.crawler.core.UncompressBodyInterceptor
com.zhiwei.crawler.core.ProxyRetryInterceptor

处理数据的顺序，依次是：ProxyRetryInterceptor -> UncompressBodyInterceptor -> DecodingChineseInterceptor，从它们的名称可知它们的功能：
ProxyRetryInterceptor: 用于处理 HTTP 请求的代理
UncompressBodyInterceptor：如果 body 是经过压缩的，由它进行的解压缩
DecodingChineseInterceptor: 针对中文进行解码

本次需求的重点代码在于 DecodingChineseInterceptor 的 fixCharset 方法中，方法的声明如下：

private static Response fixCharset(Response response) throws IOException

# fixCharset 方法步骤

1. 为了防止 HTML 开头的中文注释干扰编码探测，需要对其进行删除
2. 提取 Content-Type 和 meta 中的字符集信息
3. 从 body 中提取 1536 个字节，使用 ICU4J 框架进行编码探测，ICU4J 的探测结果并不是完全准确，它的探测结果可能存在多个，通过 JDK 的 Charset.isSupported() 选取第一个 JDK 支持的字符集，
ICU4j 的探测结果可能与正确的结果存在一定的偏差，比如：正确的字符集是《GB2312》，但是 ICU4J 的探测结果是《GB18030》，不过《GB18030》收录 70244 个，包括《GBK》和《GB2312》的全部汉字，编码问题不大。
4. 从 Content-Type 或 meta 中提取到的字符集信息，和 ICU4J 的探测结果利用 Set 进行比对，结果一致则探测结束。
注：在 JDK 的 Charset 类看来，《GB18030》=《GBK》=《GB2312》